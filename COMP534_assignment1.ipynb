{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i5afvUbhmGo"
      },
      "source": [
        "---\n",
        "\n",
        "# University of Liverpool\n",
        "\n",
        "## COMP534 - Applied AI\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpEqsZpRKtkE"
      },
      "source": [
        "This notebook is associated with Assignment 1. Use it to complete the assignment by following the instructions provided in each section, which includes a text cell describing the requirements. For additional details, see the Canvas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taBOSk4HKwZp"
      },
      "outputs": [],
      "source": [
        "# import libraries here\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score, train_test_split\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hglJVRRslqMn"
      },
      "source": [
        "# 1. **Data Management**\n",
        "\n",
        "\n",
        "In this part, you need to:\n",
        "\n",
        "1.   analyse and prepare the data. Use plots, graphs, and tables (such as histogram, box plots, scatterplots etc.) to better analyse the dataset and identify issues or potential improvements in the data, including (but not limited to) unnecessary feature/variable which can be dropped/removed, standardization, encoding, etc;\n",
        "2.   split the data and define your experimental protocol (such as cross-validation or k-fold)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szQFlMDMJYEh"
      },
      "outputs": [],
      "source": [
        "# First reaad in data set and assign valid parameter ranges based on the dataset description\n",
        "df = pd.read_csv('data/assign1-grades.csv')\n",
        "\n",
        "valid_school = ['GP', 'MS']\n",
        "valid_sex = ['F', 'M']\n",
        "valid_address = ['U', 'R']\n",
        "valid_famsize = ['GT3', 'LE3']\n",
        "valid_pstatus = ['T', 'A']\n",
        "valid_reason = ['home', 'reputation', 'course', 'other']\n",
        "valid_yes_no = ['yes', 'no']\n",
        "valid_4scale = np.arange(5)\n",
        "valid_5scale = np.arange(6)\n",
        "valid_grade = np.arange(21)\n",
        "\n",
        "minpass_grade = 12\n",
        "\n",
        "# Ensure str columns are in the proper case \n",
        "\n",
        "upper_columns = ['school', 'sex', 'address', 'famsize', 'Pstatus']\n",
        "lower_columns = ['reason', 'guardian', 'schoolsup', 'famsup', 'paid',\n",
        "                 'activities', 'nursery', 'higher', 'internet', 'romantic']\n",
        "\n",
        "for col in upper_columns:\n",
        "    df[col] = df[col].str.upper()\n",
        "\n",
        "for col in lower_columns:\n",
        "    df[col] = df[col].str.lower()\n",
        "\n",
        "# Remove null and invalid data \n",
        "\n",
        "df = df[df['school'].isin(valid_school)]\n",
        "df = df[df['sex'].isin(valid_sex)]\n",
        "df = df[df['address'].isin(valid_address)]\n",
        "df = df[df['famsize'].isin(valid_famsize)]\n",
        "df = df[df['Pstatus'].isin(valid_pstatus)]\n",
        "df = df[df['reason'].isin(valid_reason)]\n",
        "df = df[df['Grade'].isin(valid_grade)]\n",
        "\n",
        "scale4 = ['Medu', 'Fedu', 'traveltime', 'studytime']\n",
        "scale5 = ['famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health']\n",
        "yes_no = ['schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher',\n",
        "          'internet', 'romantic']\n",
        "\n",
        "for col in scale4:\n",
        "    df = df[df[col].isin(valid_4scale)]\n",
        "\n",
        "for col in scale5:\n",
        "    df = df[df[col].isin(valid_5scale)]\n",
        "\n",
        "\n",
        "for col in yes_no:\n",
        "    df = df[df[col].isin(valid_yes_no)]\n",
        "\n",
        "# Create the target column of pass/fail based on min Grade\n",
        "\n",
        "df['result'] = np.where(df['Grade'] >= minpass_grade, 'pass', 'fail')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that the initial validation is complete we can analyse the data set and look for outliers and irrelevant columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_column = ['age', 'Mjob', 'Fjob', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'absences']\n",
        "\n",
        "# Give specific rows counts\n",
        "for i in all_column:\n",
        "    value_counts = df[i].value_counts().sort_index()\n",
        "\n",
        "# Draw bar chart for each column\n",
        "for column in all_column:\n",
        "    data_counts = df[column].value_counts().sort_index()\n",
        "    plt.figure()\n",
        "    data_counts.plot(kind='bar')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Count')\n",
        "    plt.title(f'Distribution of {column}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove outliers and unnecessary columns\n",
        "\n",
        "df = df[df['age'] < 22]\n",
        "df = df.drop(columns=['paid', 'Grade'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean = df.drop(columns=[\"Unnamed: 0\"], errors=\"ignore\") # dropping the index column\n",
        "\n",
        "boolean_columns = [\"schoolsup\", \"famsup\", \"activities\", \"nursery\", \"higher\", \"internet\", \"romantic\"]\n",
        "df_clean[boolean_columns] = df_clean[boolean_columns].apply(lambda x: x.map({\"yes\": 1, \"no\":0})) #converting boolean data to numerical data representations\n",
        "\n",
        "binary_columns = [\"school\", \"sex\", \"address\", \"famsize\", \"Pstatus\", \"result\"]\n",
        "df_encoded = pd.get_dummies(df_clean, columns = binary_columns, drop_first= True ) #one-hot encoded (dummy) variables to handle categorical data\n",
        "\n",
        "categorical_columns = [\"Mjob\", \"Fjob\", \"reason\", \"guardian\"]\n",
        "df_encoded = pd.get_dummies(df_encoded, columns = categorical_columns, drop_first = False)\n",
        "\n",
        "df_encoded = df_encoded[df_encoded.columns.drop(list(df_encoded.filter(regex='_other')))]\n",
        "\n",
        "# Normalise absences\n",
        "scaler = FunctionTransformer(np.log1p, validate=True)\n",
        "df_encoded['absences'] = scaler.fit_transform(df_encoded[['absences']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "correlation_matrix = df_encoded.corr()\n",
        "plt.figure(figsize=(30,25))\n",
        "sns.heatmap (correlation_matrix, cmap= \"coolwarm\", annot = True, fmt= \".2f\", linewidths= 0.5)\n",
        "plt.title(\"Correlation Matrix Heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df_encoded.drop(columns=['result_pass']).astype(int)\n",
        "X = sm.add_constant(X)  \n",
        "\n",
        "y = df_encoded['result_pass']\n",
        "\n",
        "# Logistic Regression\n",
        "logit_model = sm.Logit(y, X)\n",
        "result = logit_model.fit()\n",
        "\n",
        "print(result.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop columns based very low correlation and low significance \n",
        "\n",
        "df_encoded = df_encoded.drop(columns=['famsup', 'guardian_mother', 'guardian_father', 'Pstatus_T', 'famsize_LE3'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vif_data = pd.DataFrame()\n",
        "X = df_encoded.drop(columns=['result_pass']).astype(int)\n",
        "\n",
        "vif_data[\"Feature\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "print(vif_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove columns \n",
        "# Note that Fedu and Medu are highligh related so we drop the one with lower correlation (Fedu)\n",
        "# Similarly with Dalc and Walc we will drop Walc\n",
        "\n",
        "df_encoded = df_encoded.drop(columns=['age', 'famrel', 'goout', 'freetime', 'Fedu', 'Walc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vif_data2 = pd.DataFrame()\n",
        "X = df_encoded.drop(columns=['result_pass']).astype(int)\n",
        "vif_data2[\"Feature\"] = X.columns\n",
        "vif_data2[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "print(vif_data2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data and initiate the 5-fold method \n",
        "kfold = KFold(5, shuffle=True, random_state=42)\n",
        "\n",
        "y = df_encoded['result_pass']\n",
        "X = df_encoded.drop(columns=['result_pass'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScTrpUW8zOp4"
      },
      "source": [
        "---\n",
        "\n",
        "# 2. **Model Training**\n",
        "\n",
        "Here, you need to:\n",
        "\n",
        "1.\tselect and compare at least three machine learning models (seen/discussed during the lectures) appropriate for your modelling;\n",
        "2.\tif there are hyperparameters in a selected algorithm, define a hyperparameter search protocol (you can define your own), and tune them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJs8HpW_zX0M"
      },
      "outputs": [],
      "source": [
        "# Implementation of SVM model\n",
        "\n",
        "# Define our classifier\n",
        "classifier = svm.SVC()\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = [\n",
        "    {'kernel': ['linear'], 'C': [0.1, 1, 10]},\n",
        "    {'kernel': ['rbf'], 'C': [0.1, 1, 10], 'gamma': ['scale', 'auto']},\n",
        "    {'kernel': ['poly'], 'C': [0.1, 1, 10], 'gamma': ['scale', 'auto'],\n",
        "     'degree': [2, 3, 4]}]\n",
        "\n",
        "# Set up grid search to find the best hyperparams\n",
        "grid_search = GridSearchCV(classifier, param_grid, cv=kfold,\n",
        "                           scoring='accuracy', return_train_score=True)\n",
        "\n",
        "print('Starting grid search to optimise hyperparams')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "print(f'best hyperparameters: {best_params}')\n",
        "\n",
        "best_svm = grid_search.best_estimator_\n",
        "\n",
        "# Calculate accuracy scores\n",
        "scores = cross_val_score(best_svm, X_train, y_train, cv=kfold, scoring='accuracy')\n",
        "\n",
        "average_acc = np.mean(scores)\n",
        "\n",
        "print(f\"Accuracy Score for each fold: {[round(score, 4) for score in scores]}\")\n",
        "print(f\"Average accuracy across 5 folds: {average_acc:.3f}\")\n",
        "\n",
        "\n",
        "# Print out scores for each param combo\n",
        "accuracys = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "accuracys = accuracys.sort_values('rank_test_score')\n",
        "print(accuracys[['param_C', 'param_kernel', 'param_gamma', 'param_degree',\n",
        "                'mean_train_score', 'mean_test_score']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implementation of RandomForest Model\n",
        "\n",
        "# Define the parameter grid for tuning\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 150, 200],          # Number of trees\n",
        "    \"max_depth\": [10, 20, 30],              # Tree depth limit\n",
        "    \"min_samples_split\": [3, 5, 10],          # Minimum samples to split a node\n",
        "    \"min_samples_leaf\": [4, 6, 8],            # Minimum samples per leaf\n",
        "    \"max_features\": [\"sqrt\", \"log2\"]          # Features considered per split\n",
        "}\n",
        "\n",
        "# Initialize Random Forest model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform Grid Search with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(rf_model, param_grid, cv=kfold, scoring=\"accuracy\", return_train_score=True)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Best Cross-Validation Accuracy:\", best_score)\n",
        "\n",
        "# Print out scores for each param combo\n",
        "accuracys = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "accuracys = accuracys.sort_values('rank_test_score')\n",
        "print(accuracys[['param_n_estimators', 'param_max_depth', 'param_min_samples_split', 'param_min_samples_leaf', 'param_max_features',\n",
        "                'mean_train_score', 'mean_test_score']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implementation of Logistic Regression Model\n",
        "\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2'],                    #l1 (Lasso), l2 (Ridge)\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'max_iter': [10000]\n",
        "}\n",
        "\n",
        "best_params = None\n",
        "best_score = 0\n",
        "accuracies = []\n",
        "conf_matrices = []\n",
        "class_reports = []\n",
        "\n",
        "for train_index, val_index in kfold.split(X_train, y_train):\n",
        "    \n",
        "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    \n",
        "    model = LogisticRegression()\n",
        "    \n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=model,\n",
        "        param_grid=param_grid,\n",
        "        scoring='accuracy'\n",
        "    )\n",
        "    \n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    if grid_search.best_score_ > best_score:\n",
        "        best_score = grid_search.best_score_\n",
        "        best_params = grid_search.best_params_\n",
        "\n",
        "    best_logistic_model = grid_search.best_estimator_\n",
        "    best_logistic_model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = best_logistic_model.predict(X_val)\n",
        "    \n",
        "    accuracies.append(accuracy_score(y_val, y_pred))\n",
        "    conf_matrices.append(confusion_matrix(y_val, y_pred))\n",
        "    class_reports.append(classification_report(y_val, y_pred, output_dict=True))\n",
        "\n",
        "avg_accuracy = np.mean(accuracies)\n",
        "\n",
        "df_results = pd.DataFrame(grid_search.cv_results_)\n",
        "\n",
        "top_10_results = df_results[['param_penalty', 'param_C', 'param_solver', 'param_max_iter', \n",
        "                             'mean_test_score', 'std_test_score', 'rank_test_score']]\\\n",
        "                    .sort_values(by='rank_test_score')\\\n",
        "                    .head(10)\n",
        "\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Best Training Accuracy: {best_score:.3f}\")\n",
        "print(f\"Average Test Accuracy: {avg_accuracy:.3f}\")\n",
        "print(\"\\nTop 10 Hyperparameter Configurations:\\n\", top_10_results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RBW58of0ZDo"
      },
      "source": [
        "---\n",
        "\n",
        "# 3. **Evaluate models**\n",
        "\n",
        "Here, you need to:\n",
        "\n",
        "1.\ttest the model (the best one you obtained from the above stage) on the testing dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHWwdXg32BEl"
      },
      "outputs": [],
      "source": [
        "# Assign our best model\n",
        "\n",
        "best_model = best_logistic_model\n",
        "\n",
        "# Compute the accuracy of our best model\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"Accuracy Score:\\n\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\")\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['0', '1'], yticklabels=['0', '1'])\n",
        "plt.title('Logistic Regression Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Compute classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred)) \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
